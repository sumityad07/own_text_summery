{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e548c21",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Artificial Intelligence is one of the most transformative technologies of our time.\n",
    "It is changing the way we work, communicate, and live.\n",
    "Machine learning is a subset of AI that learns patterns from data.\n",
    "Natural language processing enables machines to understand human language.\n",
    "Many industries are adopting AI to improve efficiency and reduce costs.\n",
    "\"\"\"\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Explicitly download the English averaged perceptron tagger\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Helper: clean and extract important tokens (nouns only)\n",
    "def preprocess_sentence(sentence):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    words = [w for w in words if w not in stop_words and w not in string.punctuation]\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    nouns = [word for word, pos in tagged if pos.startswith(\"NN\")]\n",
    "    return nouns\n",
    "\n",
    "processed_sentences = [preprocess_sentence(s) for s in sentences]\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "# Compute sentence similarity (basic Jaccard for now)\n",
    "def sentence_similarity(sen1, sen2):\n",
    "    set1, set2 = set(sen1), set(sen2)\n",
    "    if not set1 or not set2:\n",
    "        return 0\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "# Build similarity graph\n",
    "graph = nx.Graph()\n",
    "for i in range(len(processed_sentences)):\n",
    "    for j in range(len(processed_sentences)):\n",
    "        if i != j:\n",
    "            sim = sentence_similarity(processed_sentences[i], processed_sentences[j])\n",
    "            if sim > 0:\n",
    "                graph.add_edge(i, j, weight=sim)\n",
    "# Handle cases where the graph might be empty or disconnected\n",
    "if graph.number_of_nodes() == 0:\n",
    "    scores = {} # No sentences, no scores\n",
    "elif graph.number_of_edges() == 0:\n",
    "    # If no edges, PageRank might not work or be meaningful.\n",
    "    # Assign equal score to all nodes in this case.\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    scores = {node: 1.0 / num_nodes for node in graph.nodes()}\n",
    "else:\n",
    "    scores = nx.pagerank(graph)\n",
    "\n",
    "print(\"Initial PageRank scores:\", scores)\n",
    "\n",
    "# Add position score (e.g., earlier sentences get small boost)\n",
    "# Ensure all sentence indices are in scores, initializing to 0 if not present\n",
    "for i in range(len(sentences)):\n",
    "    # Use .get(key, default) to safely access scores\n",
    "    current_score = scores.get(i, 0.0) # Get current score, default to 0 if key 'i' doesn't exist\n",
    "    scores[i] = current_score + (1 / (i + 1)) * 0.1 # Update or add the score\n",
    "\n",
    "print(\"Scores after adding position boost:\", scores)\n",
    "# Rank and select top 2 sentences\n",
    "ranked_sentences = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "summary_indices = [idx for idx, _ in ranked_sentences[:2]]\n",
    "summary = \" \".join([sentences[i] for i in sorted(summary_indices)])\n",
    "\n",
    "print(\"ðŸ“Œ TextRank Summary:\\n\", summary)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
